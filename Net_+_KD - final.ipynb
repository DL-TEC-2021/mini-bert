{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zQiqyuRreYAo"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3L-F_yd1eYAu"
   },
   "source": [
    "# Mini-Bert:Using Distillation Knowledge forTraining a Minimal Bert Model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gUmUhzS5eYAw"
   },
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zsI6UPtkeYAx"
   },
   "source": [
    "We train a ``nn.TransformerEncoder`` model on a\n",
    "language modeling task. The ``nn.TransformerEncoder`` consists of multiple layers of ``nn.TransformerEncoderLayer``. A square attention mask is required because the\n",
    "self-attention layers in ``nn.TransformerEncoder`` are only allowed to attend\n",
    "the earlier positions in the sequence. For the language modeling task, any\n",
    "tokens on the future positions should be masked. \n",
    "\n",
    "To produce a probability\n",
    "distribution over output words, the output of the ``nn.TransformerEncoder``\n",
    "model is passed through a linear layer followed by a log-softmax function.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "eMyU29XqeYAy"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int,\n",
    "                 nlayers: int, dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = nn.Embedding(ntoken, d_model)\n",
    "        self.d_model = d_model\n",
    "        self.decoder = nn.Linear(d_model, ntoken)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src: Tensor, src_mask: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src: Tensor, shape [seq_len, batch_size]\n",
    "            src_mask: Tensor, shape [seq_len, seq_len]\n",
    "\n",
    "        Returns:\n",
    "            output Tensor of shape [seq_len, batch_size, ntoken]\n",
    "        \"\"\"\n",
    "        src = self.encoder(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        output = self.decoder(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "def generate_square_subsequent_mask(sz: int) -> Tensor:\n",
    "    \"\"\"Generates an upper-triangular matrix of -inf, with zeros on diag.\"\"\"\n",
    "    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QBt3X-LIeYA0"
   },
   "source": [
    "``PositionalEncoding`` module injects  information about the\n",
    "relative or absolute position of the tokens in the sequence. The\n",
    "positional encodings have the same dimension as the embeddings so that\n",
    "the two can be summed.We use ``sine`` and ``cosine`` functions to force having \n",
    "different frequencies.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "WtjoxHrPeYA1"
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Tq0YVV1eYA2"
   },
   "source": [
    "# Load data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our training and testing data is a pre curared plain text file called **wikipedia16-large.txt**. This is a 1.8GB size plain text file thatcontains  a  total  of 19 499 139 sentences. Notice that we are using a 70 percent of the total dataset for training the student model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "af30e0837a854ecbbe1f8d702f5c1835",
      "f6492a9464504fa4ab445de9625ec725",
      "61deee2b505547219299cb9804a91e05",
      "77117813fff24d6c9a22b933e802469a",
      "b8bf6078dbfc4aa7a31c7b33d00ff80c",
      "285647a6e246485d964eded4cbf5ceb8",
      "c6872cf864b54aefaf243785bbb409b4",
      "61aac86e29364a028c5b120589cefe5a",
      "ae24a824a6a94c428484339d5cb25976",
      "951734e560b3416bab04ac4619afe783",
      "e069efadf7ec4c39b4b607380d8872ab",
      "d25d46745ad54473a0851b0d96737c6d",
      "5e788eba688445aabf4cf0a1505bdf92",
      "207a22c1dd6641f49bd73887441ff4c2",
      "0b229f52ad2446d7b1f2a5974415f267",
      "777872df0e3f49adb62e92983e074920",
      "789c55958e3e4420a4440e48d7fb1d1d",
      "a83e0e8e766b48b8aa7987f4c22dc5a7",
      "178c2e32d9104696adcdeee859b61e43",
      "1f6b7a6d35c24ee0a00d803dde091e5d",
      "86c0dc0979bf45c78ab03cf6d05e60c1",
      "a113fe7bcfb54af5a0373e78c7b08b97",
      "1466b674fddd4ff48f42ee64efe362b0",
      "6d89d782468d48c0b2efd1ad969c1d22",
      "a54fda8eb1a64b99b06ffb3e691d3fe6",
      "4ef9133d58834811b6fa0edccea77821",
      "6ac1c713e9e24006b70e4468f9460ffa",
      "b0dd92d88f794e61aaf5a751974902a5",
      "b39e579362e841739415b0b78f33895b",
      "b5c6d85f18924b0a96914a387465b1a9",
      "12c0a4cf452b45b28daadb7208284b77",
      "a0ddbba095314d90a9cc8b949de97464",
      "9921c01035b84174a2679ba3cf2e1593",
      "8694bbe1ad90444db8a29552c0c093db",
      "a5734738dc8f47a0af5a6c2524a01364",
      "37747404c93a4eba8b18cd18523c589b",
      "aa25d7f1d8e143e1b6d48bf22f38ae23",
      "876103d0c62544ecafb971f34897fa29",
      "497d4ab3c1f74318b71dd7b401083416",
      "63bea9983534412db934d75aeb73691b",
      "1edfdb6bd5204892929a67705cef2aeb",
      "f2d1c366773e471c92e6434ba432d2bb",
      "25cb9f0cffbe4fad9ea46e5873dbfb92",
      "cb9a819e55aa4c5788fead49741c1ebc"
     ]
    },
    "id": "m_VsQVkqhrxn",
    "outputId": "a48eceb3-5641-4859-cd7e-d2aff81d83c6"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class SentenceIterator:\n",
    "\n",
    "    def __init__(self, dataset, batch_size, device, n = 0):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.total_lines = len(dataset)\n",
    "        self.device = device\n",
    "        self.n = n\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.n <= self.total_lines:\n",
    "            batch = tokenizer(\n",
    "                      self.dataset[self.n : self.n + self.batch_size],\n",
    "                      padding=True, \n",
    "                      truncation=True,\n",
    "                      add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
    "                      return_token_type_ids=True,\n",
    "                      return_attention_mask=True,\n",
    "                      return_tensors='pt',  # Return PyTorch tensors\n",
    "                    ).to(self.device)\n",
    "            self.n += self.batch_size\n",
    "            target = batch[\"input_ids\"]\n",
    "            batch[\"input_ids\"] = torch.tensor([np.concatenate((item[0:np.where(item == 102)[0][0]-1], [103], item[np.where(item == 102)[0][0]:len(item)]),axis=0) for item in batch[\"input_ids\"].to(\"cpu\").numpy()], dtype=torch.long).to(self.device)\n",
    "            return batch, target\n",
    "        else:\n",
    "            raise StopIteration\n",
    "\n",
    "\n",
    "def get_data(file_path, train_size):\n",
    "  with open(file_path, \"r\",encoding=\"utf-8\") as f:\n",
    "    sentences = f.readlines()\n",
    "    random.shuffle(sentences)\n",
    "    len_sentences = len(sentences)\n",
    "    len_train_sentences = int(len_sentences * train_size)\n",
    "    len_val_sentences = int((len_sentences - len_train_sentences) // 2)\n",
    "    train_sentences = sentences[0:len_train_sentences]\n",
    "    val_sentences = sentences[len_train_sentences:len_train_sentences + len_val_sentences]\n",
    "    test_sentences = sentences[len_train_sentences + len_val_sentences:len_sentences]\n",
    "    del sentences\n",
    "    return train_sentences, val_sentences, test_sentences\n",
    "\n",
    "train_data, val_data, test_data = get_data(file_path = \"wikipedia16-large.txt\", train_size = 0.7)\n",
    "\n",
    "#train_iterable = SentenceIterator(dataset = train_data, batch_size=35, device = device)\n",
    "#train_iterator = iter(train_iterable)\n",
    "\n",
    "#batch_input, batch_target = next(train_iterator)\n",
    "#print(batch_input)\n",
    "#print(batch_input[\"input_ids\"].shape)\n",
    "#print(batch_target.shape)\n",
    "#for batch_input, batch_target in train_iterator:\n",
    "#  print(batch_input.shape, batch_target.shape)\n",
    "#  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6K5ev6eweYA5"
   },
   "source": [
    "## Functions to generate input and target sequence\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MGOMtFTgeYA5"
   },
   "source": [
    "``get_batch()`` generates a pair of input-target sequences for\n",
    "the transformer model. It subdivides the source data into chunks of\n",
    "length ``bptt``. For the language modeling task, the model needs the\n",
    "following words as ``Target``. For example, with a ``bptt`` value of 2,\n",
    "we’d get the following two Variables for ``i`` = 0:\n",
    "\n",
    "![](https://github.com/pytorch/tutorials/blob/gh-pages/_downloads/_static/img/transformer_input_target.png?raw=1)\n",
    "\n",
    "\n",
    "It should be noted that the chunks are along dimension 0, consistent\n",
    "with the ``S`` dimension in the Transformer model. The batch dimension\n",
    "``N`` is along dimension 1.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d_GKaFV3eYA6"
   },
   "outputs": [],
   "source": [
    "#This is not necessary\n",
    "bptt = 35\n",
    "def get_batch(source: Tensor, i: int) -> Tuple[Tensor, Tensor]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        source: Tensor, shape [full_seq_len, batch_size]\n",
    "        i: int\n",
    "\n",
    "    Returns:\n",
    "        tuple (data, target), where data has shape [seq_len, batch_size] and\n",
    "        target has shape [seq_len * batch_size]\n",
    "    \"\"\"\n",
    "    seq_len = min(bptt, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len]\n",
    "    target = source[i+1:i+1+seq_len].reshape(-1)\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RsULpXcVeYA7"
   },
   "source": [
    "## Initialize Hyper Parameters and Variables\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKTx899PeYA7"
   },
   "source": [
    "The model hyperparameters are defined below. The vocab size is\n",
    "equal to the length of the vocab object.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6x7fWe59eYA8"
   },
   "outputs": [],
   "source": [
    "ntokens = 30522  # size of vocabulary in BERT\n",
    "batch_size = 20\n",
    "emsize = 512  # embedding dimension\n",
    "d_hid = emsize * 4  # dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 2  # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 2  # number of heads in nn.MultiheadAttention\n",
    "dropout = 0.2  # dropout probability\n",
    "temperature = 0.5 # temperature for kd\n",
    "alpha = 0.3 # how important is the output of the student\n",
    "from os import path\n",
    "path_file = \"/content/drive/MyDrive/Project2/transformer1.pt\"\n",
    "model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout).to(device)\n",
    "if path.exists(path_file):\n",
    "  model.load_state_dict(torch.load(path_file, map_location=torch.device(device)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Teacher Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our teacher model we are using the **bert-base-uncased** variant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "cdf5783874b8451385df9c02c019b00f",
      "1f8e712cc9b340adaab174baccd8cd7b",
      "ac77a78822564acabfd3d28c7c9f6253",
      "ea7fcd11d8f240d79912ea3afcde36f6",
      "d686a57de7414161b0476d4aee408132",
      "4ac1e21fe5cf43b2bed6f86a247d35df",
      "4f62ba5ef285473e8b5dbfc6293860ba",
      "2170a8bbfbbc4ed69d588c1046a1fd2f",
      "6c28459b30d14043aa175c8ccaa5943c",
      "36391c860e3848ce9ce01055a143c862",
      "0c6efb62cd3a4d09a689b9e3536bdd03"
     ]
    },
    "id": "XET1X1gnI0AC",
    "outputId": "5bc1be1d-8446-43d1-9fa6-0526fbe887dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForMaskedLM\n",
    "\n",
    "teacher_model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "teacher_model.eval()\n",
    "teacher_model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hm_vjbzZeYA8"
   },
   "source": [
    "## Student Model training\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCO1inZVeYA9"
   },
   "source": [
    "We use CrossEntropyLoss with  Stochastic Gradient Descent as the optimizer. The learning rate is initially set to 5.0. We use `nn.utils.clip_grad_norm\\_ <https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm_.html>`__\n",
    "to prevent gradients from exploding.\n",
    "\n",
    "During the training, a single batch consists of 200 sentences. In this particular case we have a total of 19 499 139 sentences wich is about 1.8GB of text data. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4nmbKzROeYA9"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterionKL = nn.KLDivLoss(reduction = \"batchmean\")\n",
    "lr = 5.0  # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "\n",
    "def dist_loss(t, s, T):\n",
    "    prob_t = F.softmax(t/T, dim=1)\n",
    "    log_prob_s = F.log_softmax(s/T, dim=1)\n",
    "    dist_loss = -(prob_t*log_prob_s).sum(dim=1).mean()\n",
    "    return dist_loss\n",
    "\n",
    "def train(model: nn.Module) -> None:\n",
    "    model.train()  # turn on train mode\n",
    "    total_loss = 0.\n",
    "    log_interval = 200\n",
    "    start_time = time.time()\n",
    "    src_mask = generate_square_subsequent_mask(batch_size).to(device)\n",
    "    num_batches = len(train_data) // batch_size\n",
    "    batch = 0\n",
    "    train_iterable = SentenceIterator(dataset = train_data, batch_size=batch_size, device = device)\n",
    "    train_iterator = iter(train_iterable)\n",
    "    for batch_input, batch_target in train_iterator:\n",
    "\n",
    "        current_batch_size = batch_input[\"input_ids\"].size(0)\n",
    "        if batch_size != current_batch_size:  # only on last batch\n",
    "            src_mask = src_mask[:current_batch_size, :current_batch_size]\n",
    "\n",
    "        with torch.no_grad():\n",
    "          output_teacher = teacher_model(**batch_input, labels=batch_target)\n",
    "        \n",
    "        output = model(batch_input[\"input_ids\"], src_mask)\n",
    "        student_loss = criterion(output.view(-1, ntokens), batch_target.reshape(-1))\n",
    "\n",
    "        #ditillation_loss = criterionKL(\n",
    "        #    F.log_softmax(output / temperature, dim=1),\n",
    "        #    F.softmax(output_teacher.logits / temperature, dim=1)\n",
    "        #)\n",
    "\n",
    "        #loss = alpha * student_loss + (1 - alpha) * ditillation_loss\n",
    "\n",
    "        distillation_loss = dist_loss(output_teacher.logits, output, temperature)\n",
    "\n",
    "        loss = student_loss + distillation_loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "            cur_loss = total_loss / log_interval\n",
    "            ppl = math.exp(cur_loss)\n",
    "            print(f'| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | '\n",
    "                  f'lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | '\n",
    "                  f'loss {cur_loss:5.2f} | ppl {ppl:8.2f}')\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "        if batch % 1000 == 0 and batch > 0:\n",
    "            torch.save(model.state_dict(), path_file)\n",
    "        batch += 1\n",
    "\n",
    "def evaluate(model: nn.Module, eval_data) -> float:\n",
    "    model.eval()  # turn on evaluation mode\n",
    "    total_loss = 0.\n",
    "    src_mask = generate_square_subsequent_mask(batch_size).to(device)\n",
    "    with torch.no_grad():\n",
    "        val_iterable = SentenceIterator(dataset = eval_data, batch_size=batch_size, device = device)\n",
    "        val_iterator = iter(val_iterable)\n",
    "        for batch_input, batch_target in val_iterator:\n",
    "\n",
    "            current_batch_size = batch_input[\"input_ids\"].size(0)\n",
    "            if batch_size != current_batch_size:  # only on last batch\n",
    "                src_mask = src_mask[:current_batch_size, :current_batch_size]\n",
    "\n",
    "            output = model(batch_input[\"input_ids\"], src_mask)\n",
    "            output_flat = output.view(-1, ntokens)\n",
    "            total_loss += batch_size * criterion(output_flat, batch_target).item()\n",
    "    return total_loss / (len(eval_data) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CLKi4r4teYA-"
   },
   "source": [
    "Loop over epochs. Save the model if the validation loss is the best\n",
    "we've seen so far. Adjust the learning rate after each epoch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3rZPQ147eYA-",
    "outputId": "6d376653-2b4f-40e6-eacd-04b60d888b9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   200/682469 batches | lr 5.00 | ms/batch 44.85 | loss  7.91 | ppl  2712.08\n",
      "| epoch   1 |   400/682469 batches | lr 5.00 | ms/batch 43.56 | loss  5.35 | ppl   210.74\n",
      "| epoch   1 |   600/682469 batches | lr 5.00 | ms/batch 43.49 | loss  5.01 | ppl   149.50\n",
      "| epoch   1 |   800/682469 batches | lr 5.00 | ms/batch 42.72 | loss  4.71 | ppl   111.57\n",
      "| epoch   1 |  1000/682469 batches | lr 5.00 | ms/batch 43.01 | loss  4.57 | ppl    96.61\n",
      "| epoch   1 |  1200/682469 batches | lr 5.00 | ms/batch 45.31 | loss  4.50 | ppl    90.42\n",
      "| epoch   1 |  1400/682469 batches | lr 5.00 | ms/batch 43.67 | loss  4.35 | ppl    77.30\n",
      "| epoch   1 |  1600/682469 batches | lr 5.00 | ms/batch 43.01 | loss  4.25 | ppl    69.91\n",
      "| epoch   1 |  1800/682469 batches | lr 5.00 | ms/batch 43.11 | loss  4.17 | ppl    64.64\n",
      "| epoch   1 |  2000/682469 batches | lr 5.00 | ms/batch 44.43 | loss  4.12 | ppl    61.33\n",
      "| epoch   1 |  2200/682469 batches | lr 5.00 | ms/batch 46.21 | loss  4.08 | ppl    59.24\n",
      "| epoch   1 |  2400/682469 batches | lr 5.00 | ms/batch 43.82 | loss  4.00 | ppl    54.67\n",
      "| epoch   1 |  2600/682469 batches | lr 5.00 | ms/batch 43.58 | loss  3.95 | ppl    51.71\n",
      "| epoch   1 |  2800/682469 batches | lr 5.00 | ms/batch 43.04 | loss  3.89 | ppl    48.71\n",
      "| epoch   1 |  3000/682469 batches | lr 5.00 | ms/batch 42.71 | loss  3.86 | ppl    47.45\n",
      "| epoch   1 |  3200/682469 batches | lr 5.00 | ms/batch 46.11 | loss  3.83 | ppl    45.84\n",
      "| epoch   1 |  3400/682469 batches | lr 5.00 | ms/batch 42.71 | loss  3.81 | ppl    44.93\n",
      "| epoch   1 |  3600/682469 batches | lr 5.00 | ms/batch 43.43 | loss  3.76 | ppl    43.08\n",
      "| epoch   1 |  3800/682469 batches | lr 5.00 | ms/batch 42.86 | loss  3.74 | ppl    41.95\n",
      "| epoch   1 |  4000/682469 batches | lr 5.00 | ms/batch 42.55 | loss  3.69 | ppl    40.23\n",
      "| epoch   1 |  4200/682469 batches | lr 5.00 | ms/batch 45.82 | loss  3.68 | ppl    39.47\n",
      "| epoch   1 |  4400/682469 batches | lr 5.00 | ms/batch 43.09 | loss  3.67 | ppl    39.09\n",
      "| epoch   1 |  4600/682469 batches | lr 5.00 | ms/batch 43.32 | loss  3.65 | ppl    38.49\n",
      "| epoch   1 |  4800/682469 batches | lr 5.00 | ms/batch 42.78 | loss  3.65 | ppl    38.43\n",
      "| epoch   1 |  5000/682469 batches | lr 5.00 | ms/batch 43.17 | loss  3.59 | ppl    36.17\n",
      "| epoch   1 |  5200/682469 batches | lr 5.00 | ms/batch 46.15 | loss  3.57 | ppl    35.35\n",
      "| epoch   1 |  5400/682469 batches | lr 5.00 | ms/batch 44.23 | loss  3.55 | ppl    34.82\n",
      "| epoch   1 |  5600/682469 batches | lr 5.00 | ms/batch 42.67 | loss  3.54 | ppl    34.49\n",
      "| epoch   1 |  5800/682469 batches | lr 5.00 | ms/batch 42.35 | loss  3.50 | ppl    33.16\n",
      "| epoch   1 |  6000/682469 batches | lr 5.00 | ms/batch 42.60 | loss  3.48 | ppl    32.52\n",
      "| epoch   1 |  6200/682469 batches | lr 5.00 | ms/batch 44.99 | loss  3.46 | ppl    31.89\n",
      "| epoch   1 |  6400/682469 batches | lr 5.00 | ms/batch 42.40 | loss  3.45 | ppl    31.37\n",
      "| epoch   1 |  6600/682469 batches | lr 5.00 | ms/batch 43.17 | loss  3.47 | ppl    32.01\n",
      "| epoch   1 |  6800/682469 batches | lr 5.00 | ms/batch 43.09 | loss  3.42 | ppl    30.45\n",
      "| epoch   1 |  7000/682469 batches | lr 5.00 | ms/batch 42.89 | loss  3.41 | ppl    30.12\n",
      "| epoch   1 |  7200/682469 batches | lr 5.00 | ms/batch 45.54 | loss  3.39 | ppl    29.80\n",
      "| epoch   1 |  7400/682469 batches | lr 5.00 | ms/batch 43.39 | loss  3.38 | ppl    29.47\n",
      "| epoch   1 |  7600/682469 batches | lr 5.00 | ms/batch 42.48 | loss  3.37 | ppl    29.02\n",
      "| epoch   1 |  7800/682469 batches | lr 5.00 | ms/batch 42.35 | loss  3.35 | ppl    28.39\n",
      "| epoch   1 |  8000/682469 batches | lr 5.00 | ms/batch 43.44 | loss  3.35 | ppl    28.48\n",
      "| epoch   1 |  8200/682469 batches | lr 5.00 | ms/batch 45.12 | loss  3.33 | ppl    27.88\n",
      "| epoch   1 |  8400/682469 batches | lr 5.00 | ms/batch 43.88 | loss  3.32 | ppl    27.69\n",
      "| epoch   1 |  8600/682469 batches | lr 5.00 | ms/batch 44.76 | loss  3.34 | ppl    28.19\n",
      "| epoch   1 |  8800/682469 batches | lr 5.00 | ms/batch 44.24 | loss  3.31 | ppl    27.48\n",
      "| epoch   1 |  9000/682469 batches | lr 5.00 | ms/batch 43.59 | loss  3.27 | ppl    26.38\n",
      "| epoch   1 |  9200/682469 batches | lr 5.00 | ms/batch 46.11 | loss  3.29 | ppl    26.80\n",
      "| epoch   1 |  9400/682469 batches | lr 5.00 | ms/batch 43.16 | loss  3.27 | ppl    26.24\n",
      "| epoch   1 |  9600/682469 batches | lr 5.00 | ms/batch 43.09 | loss  3.26 | ppl    26.01\n",
      "| epoch   1 |  9800/682469 batches | lr 5.00 | ms/batch 42.88 | loss  3.27 | ppl    26.26\n",
      "| epoch   1 | 10000/682469 batches | lr 5.00 | ms/batch 43.65 | loss  3.26 | ppl    25.95\n",
      "| epoch   1 | 10200/682469 batches | lr 5.00 | ms/batch 47.60 | loss  3.26 | ppl    26.13\n",
      "| epoch   1 | 10400/682469 batches | lr 5.00 | ms/batch 43.45 | loss  3.24 | ppl    25.60\n",
      "| epoch   1 | 10600/682469 batches | lr 5.00 | ms/batch 43.02 | loss  3.22 | ppl    24.96\n",
      "| epoch   1 | 10800/682469 batches | lr 5.00 | ms/batch 42.62 | loss  3.20 | ppl    24.46\n",
      "| epoch   1 | 11000/682469 batches | lr 5.00 | ms/batch 42.57 | loss  3.20 | ppl    24.44\n",
      "| epoch   1 | 11200/682469 batches | lr 5.00 | ms/batch 45.32 | loss  3.19 | ppl    24.22\n",
      "| epoch   1 | 11400/682469 batches | lr 5.00 | ms/batch 44.58 | loss  3.19 | ppl    24.28\n",
      "| epoch   1 | 11600/682469 batches | lr 5.00 | ms/batch 43.20 | loss  3.19 | ppl    24.39\n",
      "| epoch   1 | 11800/682469 batches | lr 5.00 | ms/batch 43.17 | loss  3.18 | ppl    24.14\n",
      "| epoch   1 | 12000/682469 batches | lr 5.00 | ms/batch 42.13 | loss  3.15 | ppl    23.26\n",
      "| epoch   1 | 12200/682469 batches | lr 5.00 | ms/batch 44.82 | loss  3.13 | ppl    22.93\n",
      "| epoch   1 | 12400/682469 batches | lr 5.00 | ms/batch 43.51 | loss  3.15 | ppl    23.37\n",
      "| epoch   1 | 12600/682469 batches | lr 5.00 | ms/batch 42.52 | loss  3.13 | ppl    22.92\n",
      "| epoch   1 | 12800/682469 batches | lr 5.00 | ms/batch 42.66 | loss  3.12 | ppl    22.71\n",
      "| epoch   1 | 13000/682469 batches | lr 5.00 | ms/batch 42.75 | loss  3.12 | ppl    22.72\n",
      "| epoch   1 | 13200/682469 batches | lr 5.00 | ms/batch 45.23 | loss  3.12 | ppl    22.62\n",
      "| epoch   1 | 13400/682469 batches | lr 5.00 | ms/batch 43.20 | loss  3.11 | ppl    22.37\n",
      "| epoch   1 | 13600/682469 batches | lr 5.00 | ms/batch 42.52 | loss  3.09 | ppl    21.99\n",
      "| epoch   1 | 13800/682469 batches | lr 5.00 | ms/batch 42.26 | loss  3.07 | ppl    21.64\n",
      "| epoch   1 | 14000/682469 batches | lr 5.00 | ms/batch 42.50 | loss  3.13 | ppl    22.87\n",
      "| epoch   1 | 14200/682469 batches | lr 5.00 | ms/batch 46.98 | loss  3.11 | ppl    22.42\n",
      "| epoch   1 | 14400/682469 batches | lr 5.00 | ms/batch 43.23 | loss  3.09 | ppl    21.89\n",
      "| epoch   1 | 14600/682469 batches | lr 5.00 | ms/batch 42.39 | loss  3.07 | ppl    21.51\n",
      "| epoch   1 | 14800/682469 batches | lr 5.00 | ms/batch 42.52 | loss  3.09 | ppl    22.08\n",
      "| epoch   1 | 15000/682469 batches | lr 5.00 | ms/batch 42.10 | loss  3.05 | ppl    21.01\n",
      "| epoch   1 | 15200/682469 batches | lr 5.00 | ms/batch 45.32 | loss  3.04 | ppl    20.92\n",
      "| epoch   1 | 15400/682469 batches | lr 5.00 | ms/batch 43.27 | loss  3.05 | ppl    21.10\n",
      "| epoch   1 | 15600/682469 batches | lr 5.00 | ms/batch 43.02 | loss  3.07 | ppl    21.65\n",
      "| epoch   1 | 15800/682469 batches | lr 5.00 | ms/batch 43.05 | loss  3.03 | ppl    20.80\n",
      "| epoch   1 | 16000/682469 batches | lr 5.00 | ms/batch 44.03 | loss  3.05 | ppl    21.08\n",
      "| epoch   1 | 16200/682469 batches | lr 5.00 | ms/batch 45.35 | loss  3.03 | ppl    20.75\n",
      "| epoch   1 | 16400/682469 batches | lr 5.00 | ms/batch 43.22 | loss  3.01 | ppl    20.37\n",
      "| epoch   1 | 16600/682469 batches | lr 5.00 | ms/batch 43.54 | loss  3.03 | ppl    20.67\n",
      "| epoch   1 | 16800/682469 batches | lr 5.00 | ms/batch 42.82 | loss  3.02 | ppl    20.50\n",
      "| epoch   1 | 17000/682469 batches | lr 5.00 | ms/batch 43.05 | loss  3.03 | ppl    20.77\n",
      "| epoch   1 | 17200/682469 batches | lr 5.00 | ms/batch 44.70 | loss  3.00 | ppl    20.02\n",
      "| epoch   1 | 17400/682469 batches | lr 5.00 | ms/batch 42.98 | loss  2.99 | ppl    19.93\n",
      "| epoch   1 | 17600/682469 batches | lr 5.00 | ms/batch 42.86 | loss  2.99 | ppl    19.86\n",
      "| epoch   1 | 17800/682469 batches | lr 5.00 | ms/batch 42.59 | loss  3.02 | ppl    20.58\n",
      "| epoch   1 | 18000/682469 batches | lr 5.00 | ms/batch 43.40 | loss  3.05 | ppl    21.04\n",
      "| epoch   1 | 18200/682469 batches | lr 5.00 | ms/batch 45.90 | loss  3.01 | ppl    20.22\n",
      "| epoch   1 | 18400/682469 batches | lr 5.00 | ms/batch 43.22 | loss  3.00 | ppl    20.00\n",
      "| epoch   1 | 18600/682469 batches | lr 5.00 | ms/batch 42.94 | loss  2.97 | ppl    19.46\n",
      "| epoch   1 | 18800/682469 batches | lr 5.00 | ms/batch 42.64 | loss  2.98 | ppl    19.68\n",
      "| epoch   1 | 19000/682469 batches | lr 5.00 | ms/batch 42.76 | loss  2.96 | ppl    19.34\n",
      "| epoch   1 | 19200/682469 batches | lr 5.00 | ms/batch 44.94 | loss  2.99 | ppl    19.80\n",
      "| epoch   1 | 19400/682469 batches | lr 5.00 | ms/batch 43.43 | loss  2.97 | ppl    19.50\n",
      "| epoch   1 | 19600/682469 batches | lr 5.00 | ms/batch 42.12 | loss  2.97 | ppl    19.43\n",
      "| epoch   1 | 19800/682469 batches | lr 5.00 | ms/batch 43.73 | loss  2.97 | ppl    19.40\n",
      "| epoch   1 | 20000/682469 batches | lr 5.00 | ms/batch 42.23 | loss  2.94 | ppl    18.96\n",
      "| epoch   1 | 20200/682469 batches | lr 5.00 | ms/batch 44.64 | loss  2.93 | ppl    18.80\n",
      "| epoch   1 | 20400/682469 batches | lr 5.00 | ms/batch 42.85 | loss  2.94 | ppl    18.96\n",
      "| epoch   1 | 20600/682469 batches | lr 5.00 | ms/batch 43.58 | loss  2.93 | ppl    18.72\n",
      "| epoch   1 | 20800/682469 batches | lr 5.00 | ms/batch 43.51 | loss  2.92 | ppl    18.54\n",
      "| epoch   1 | 21000/682469 batches | lr 5.00 | ms/batch 43.06 | loss  2.94 | ppl    18.93\n",
      "| epoch   1 | 21200/682469 batches | lr 5.00 | ms/batch 45.26 | loss  2.93 | ppl    18.65\n",
      "| epoch   1 | 21400/682469 batches | lr 5.00 | ms/batch 43.62 | loss  2.93 | ppl    18.73\n",
      "| epoch   1 | 21600/682469 batches | lr 5.00 | ms/batch 42.82 | loss  2.92 | ppl    18.62\n",
      "| epoch   1 | 21800/682469 batches | lr 5.00 | ms/batch 43.87 | loss  2.93 | ppl    18.71\n",
      "| epoch   1 | 22000/682469 batches | lr 5.00 | ms/batch 42.56 | loss  2.89 | ppl    17.97\n",
      "| epoch   1 | 22200/682469 batches | lr 5.00 | ms/batch 44.87 | loss  2.89 | ppl    18.00\n",
      "| epoch   1 | 22400/682469 batches | lr 5.00 | ms/batch 42.89 | loss  2.89 | ppl    18.00\n",
      "| epoch   1 | 22600/682469 batches | lr 5.00 | ms/batch 42.39 | loss  2.88 | ppl    17.83\n",
      "| epoch   1 | 22800/682469 batches | lr 5.00 | ms/batch 43.67 | loss  2.93 | ppl    18.71\n",
      "| epoch   1 | 23000/682469 batches | lr 5.00 | ms/batch 43.28 | loss  2.90 | ppl    18.18\n",
      "| epoch   1 | 23200/682469 batches | lr 5.00 | ms/batch 44.57 | loss  2.85 | ppl    17.34\n",
      "| epoch   1 | 23400/682469 batches | lr 5.00 | ms/batch 43.65 | loss  2.93 | ppl    18.79\n",
      "| epoch   1 | 23600/682469 batches | lr 5.00 | ms/batch 43.34 | loss  2.90 | ppl    18.24\n",
      "| epoch   1 | 23800/682469 batches | lr 5.00 | ms/batch 42.42 | loss  2.86 | ppl    17.45\n",
      "| epoch   1 | 24000/682469 batches | lr 5.00 | ms/batch 42.40 | loss  2.88 | ppl    17.78\n",
      "| epoch   1 | 24200/682469 batches | lr 5.00 | ms/batch 45.29 | loss  2.86 | ppl    17.46\n",
      "| epoch   1 | 24400/682469 batches | lr 5.00 | ms/batch 43.53 | loss  2.87 | ppl    17.60\n",
      "| epoch   1 | 24600/682469 batches | lr 5.00 | ms/batch 43.23 | loss  2.88 | ppl    17.75\n",
      "| epoch   1 | 24800/682469 batches | lr 5.00 | ms/batch 43.70 | loss  2.90 | ppl    18.12\n",
      "| epoch   1 | 25000/682469 batches | lr 5.00 | ms/batch 43.07 | loss  2.88 | ppl    17.76\n",
      "| epoch   1 | 25200/682469 batches | lr 5.00 | ms/batch 46.15 | loss  2.86 | ppl    17.47\n",
      "| epoch   1 | 25400/682469 batches | lr 5.00 | ms/batch 42.58 | loss  2.86 | ppl    17.51\n",
      "| epoch   1 | 25600/682469 batches | lr 5.00 | ms/batch 42.19 | loss  2.82 | ppl    16.78\n",
      "| epoch   1 | 25800/682469 batches | lr 5.00 | ms/batch 42.08 | loss  2.83 | ppl    17.03\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float('inf')\n",
    "epochs = 1\n",
    "best_model = None\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(model)\n",
    "    val_loss = evaluate(model, val_data)\n",
    "    val_ppl = math.exp(val_loss)\n",
    "    elapsed = time.time() - epoch_start_time\n",
    "    print('-' * 89)\n",
    "    print(f'| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | '\n",
    "          f'valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}')\n",
    "    print('-' * 89)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = copy.deepcopy(model)\n",
    "        torch.save(best_model.state_dict(), path_file)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PTU1EsrOeYA_"
   },
   "source": [
    "Evaluate the best model on the test dataset\n",
    "-------------------------------------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FtLvVpeleYA_",
    "outputId": "8a28623f-24bb-4612-b315-bfa1bfa1d69e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss  0.22 | test ppl     1.25\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "test_loss = evaluate(best_model, test_data)\n",
    "test_ppl = math.exp(test_loss)\n",
    "print('=' * 89)\n",
    "print(f'| End of training | test loss {test_loss:5.2f} | '\n",
    "      f'test ppl {test_ppl:8.2f}')\n",
    "print('=' * 89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5GktJJN0RmIT",
    "outputId": "53094099-874a-4594-c76e-41d0e8eb2369"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 3000, 2003, 1996, 3007, 1997,  103, 1012,  102]])\n",
      "['[CLS]', 'paris', 'is', 'the', 'capital', 'of', '[MASK]', '.', '[SEP]']\n",
      "input size torch.Size([1, 9])\n",
      "src mask tensor([[0.]])\n",
      "Teacher prediction\n",
      "2605\n",
      "['france']\n",
      "Student prediction\n",
      "tensor([ 101, 3000, 2003, 1996, 3007, 1997, 1012, 1012,  102])\n",
      "['[CLS]', 'paris', 'is', 'the', 'capital', 'of', '.', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "#torch.save(best_model.state_dict(), \"/content/drive/MyDrive/Project2/transformer3.pt\")\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import torch\n",
    "\n",
    "device = 'cpu'#torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "teacher_model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "teacher_model.to(device)\n",
    "\n",
    "ntokens = 30522  # size of vocabulary in BERT\n",
    "batch_size = 20\n",
    "emsize = 512  # embedding dimension\n",
    "d_hid = emsize * 4  # dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 2  # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 2  # number of heads in nn.MultiheadAttention\n",
    "dropout = 0.2  # dropout probability\n",
    "path_file = \"/content/drive/MyDrive/Project2/transformer1.pt\"\n",
    "\n",
    "best_model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout)\n",
    "best_model.load_state_dict(torch.load(path_file, map_location=torch.device(device)))\n",
    "sentence = [\"Paris is the capital of [MASK].\"]\n",
    "target = tokenizer([\"Paris is the capital of France.\"], return_tensors='pt')[\"input_ids\"].to(device)\n",
    "\n",
    "src_mask = generate_square_subsequent_mask(1).to(device)\n",
    "sentence_data = tokenizer(\n",
    "                      sentence,\n",
    "                      padding=True, \n",
    "                      truncation=True,\n",
    "                      add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
    "                      return_token_type_ids=True,\n",
    "                      return_attention_mask=True,\n",
    "                      return_tensors='pt',  # Return PyTorch tensors\n",
    "                    ).to(device)\n",
    "print(sentence_data[\"input_ids\"])\n",
    "print(tokenizer.convert_ids_to_tokens(sentence_data[\"input_ids\"][0]))\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "  print(\"input size\", sentence_data[\"input_ids\"].shape)\n",
    "  print(\"src mask\", src_mask)\n",
    "  output = best_model(sentence_data[\"input_ids\"].to(device), src_mask.to(device))#.reshape(-1, ntokens)\n",
    "  \"\"\"\n",
    "  output_flat = output.view(-1, ntokens)\n",
    "  print(\"output size\", output.shape)\n",
    "  print(output)\n",
    "  print(\"output flat size\", output_flat.shape)\n",
    "  print(output_flat)\n",
    "  print(nn.Softmax(dim=1)(output_flat))\n",
    "  result_index = torch.argmax(nn.Softmax(dim=1)(output_flat), dim=1)\n",
    "  print(result_index)\n",
    "  print(sentence)\n",
    "  print(tokenizer.convert_ids_to_tokens(sentence_data[0]))\n",
    "  print(tokenizer.convert_ids_to_tokens(result_index))\n",
    "  \"\"\"\n",
    "  output_teacher = teacher_model(**sentence_data, labels=target)\n",
    "\n",
    "  masked_index = 6\n",
    "\n",
    "  print(\"Teacher prediction\")\n",
    "  predicted_index = torch.argmax(output_teacher.logits[0, masked_index]).item()\n",
    "  print(predicted_index)\n",
    "  predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])\n",
    "  print(predicted_token)\n",
    "\n",
    "\n",
    "  print(\"Student prediction\")\n",
    "  predicted_index = torch.argmax(output.reshape(-1, ntokens), dim=1)\n",
    "  print(predicted_index)\n",
    "  predicted_token = tokenizer.convert_ids_to_tokens(predicted_index)\n",
    "  print(predicted_token)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Net_+_KD.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0b229f52ad2446d7b1f2a5974415f267": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1f6b7a6d35c24ee0a00d803dde091e5d",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_178c2e32d9104696adcdeee859b61e43",
      "value": 28
     }
    },
    "0c6efb62cd3a4d09a689b9e3536bdd03": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "12c0a4cf452b45b28daadb7208284b77": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1466b674fddd4ff48f42ee64efe362b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a54fda8eb1a64b99b06ffb3e691d3fe6",
       "IPY_MODEL_4ef9133d58834811b6fa0edccea77821",
       "IPY_MODEL_6ac1c713e9e24006b70e4468f9460ffa"
      ],
      "layout": "IPY_MODEL_6d89d782468d48c0b2efd1ad969c1d22"
     }
    },
    "178c2e32d9104696adcdeee859b61e43": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1edfdb6bd5204892929a67705cef2aeb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1f6b7a6d35c24ee0a00d803dde091e5d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f8e712cc9b340adaab174baccd8cd7b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "207a22c1dd6641f49bd73887441ff4c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a83e0e8e766b48b8aa7987f4c22dc5a7",
      "placeholder": "​",
      "style": "IPY_MODEL_789c55958e3e4420a4440e48d7fb1d1d",
      "value": "Downloading: 100%"
     }
    },
    "2170a8bbfbbc4ed69d588c1046a1fd2f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "25cb9f0cffbe4fad9ea46e5873dbfb92": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "285647a6e246485d964eded4cbf5ceb8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "36391c860e3848ce9ce01055a143c862": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "37747404c93a4eba8b18cd18523c589b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_63bea9983534412db934d75aeb73691b",
      "placeholder": "​",
      "style": "IPY_MODEL_497d4ab3c1f74318b71dd7b401083416",
      "value": "Downloading: 100%"
     }
    },
    "497d4ab3c1f74318b71dd7b401083416": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4ac1e21fe5cf43b2bed6f86a247d35df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4ef9133d58834811b6fa0edccea77821": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_12c0a4cf452b45b28daadb7208284b77",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b5c6d85f18924b0a96914a387465b1a9",
      "value": 466062
     }
    },
    "4f62ba5ef285473e8b5dbfc6293860ba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e788eba688445aabf4cf0a1505bdf92": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "61aac86e29364a028c5b120589cefe5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "61deee2b505547219299cb9804a91e05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c6872cf864b54aefaf243785bbb409b4",
      "placeholder": "​",
      "style": "IPY_MODEL_285647a6e246485d964eded4cbf5ceb8",
      "value": "Downloading: 100%"
     }
    },
    "63bea9983534412db934d75aeb73691b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ac1c713e9e24006b70e4468f9460ffa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9921c01035b84174a2679ba3cf2e1593",
      "placeholder": "​",
      "style": "IPY_MODEL_a0ddbba095314d90a9cc8b949de97464",
      "value": " 455k/455k [00:00&lt;00:00, 649kB/s]"
     }
    },
    "6c28459b30d14043aa175c8ccaa5943c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6d89d782468d48c0b2efd1ad969c1d22": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77117813fff24d6c9a22b933e802469a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ae24a824a6a94c428484339d5cb25976",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_61aac86e29364a028c5b120589cefe5a",
      "value": 231508
     }
    },
    "777872df0e3f49adb62e92983e074920": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a113fe7bcfb54af5a0373e78c7b08b97",
      "placeholder": "​",
      "style": "IPY_MODEL_86c0dc0979bf45c78ab03cf6d05e60c1",
      "value": " 28.0/28.0 [00:00&lt;00:00, 1.15kB/s]"
     }
    },
    "789c55958e3e4420a4440e48d7fb1d1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8694bbe1ad90444db8a29552c0c093db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_37747404c93a4eba8b18cd18523c589b",
       "IPY_MODEL_aa25d7f1d8e143e1b6d48bf22f38ae23",
       "IPY_MODEL_876103d0c62544ecafb971f34897fa29"
      ],
      "layout": "IPY_MODEL_a5734738dc8f47a0af5a6c2524a01364"
     }
    },
    "86c0dc0979bf45c78ab03cf6d05e60c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "876103d0c62544ecafb971f34897fa29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cb9a819e55aa4c5788fead49741c1ebc",
      "placeholder": "​",
      "style": "IPY_MODEL_25cb9f0cffbe4fad9ea46e5873dbfb92",
      "value": " 570/570 [00:00&lt;00:00, 25.8kB/s]"
     }
    },
    "951734e560b3416bab04ac4619afe783": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9921c01035b84174a2679ba3cf2e1593": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a0ddbba095314d90a9cc8b949de97464": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a113fe7bcfb54af5a0373e78c7b08b97": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a54fda8eb1a64b99b06ffb3e691d3fe6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b39e579362e841739415b0b78f33895b",
      "placeholder": "​",
      "style": "IPY_MODEL_b0dd92d88f794e61aaf5a751974902a5",
      "value": "Downloading: 100%"
     }
    },
    "a5734738dc8f47a0af5a6c2524a01364": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a83e0e8e766b48b8aa7987f4c22dc5a7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aa25d7f1d8e143e1b6d48bf22f38ae23": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f2d1c366773e471c92e6434ba432d2bb",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1edfdb6bd5204892929a67705cef2aeb",
      "value": 570
     }
    },
    "ac77a78822564acabfd3d28c7c9f6253": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4f62ba5ef285473e8b5dbfc6293860ba",
      "placeholder": "​",
      "style": "IPY_MODEL_4ac1e21fe5cf43b2bed6f86a247d35df",
      "value": "Downloading: 100%"
     }
    },
    "ae24a824a6a94c428484339d5cb25976": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af30e0837a854ecbbe1f8d702f5c1835": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_61deee2b505547219299cb9804a91e05",
       "IPY_MODEL_77117813fff24d6c9a22b933e802469a",
       "IPY_MODEL_b8bf6078dbfc4aa7a31c7b33d00ff80c"
      ],
      "layout": "IPY_MODEL_f6492a9464504fa4ab445de9625ec725"
     }
    },
    "b0dd92d88f794e61aaf5a751974902a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b39e579362e841739415b0b78f33895b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b5c6d85f18924b0a96914a387465b1a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b8bf6078dbfc4aa7a31c7b33d00ff80c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e069efadf7ec4c39b4b607380d8872ab",
      "placeholder": "​",
      "style": "IPY_MODEL_951734e560b3416bab04ac4619afe783",
      "value": " 226k/226k [00:00&lt;00:00, 806kB/s]"
     }
    },
    "c6872cf864b54aefaf243785bbb409b4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb9a819e55aa4c5788fead49741c1ebc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cdf5783874b8451385df9c02c019b00f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ac77a78822564acabfd3d28c7c9f6253",
       "IPY_MODEL_ea7fcd11d8f240d79912ea3afcde36f6",
       "IPY_MODEL_d686a57de7414161b0476d4aee408132"
      ],
      "layout": "IPY_MODEL_1f8e712cc9b340adaab174baccd8cd7b"
     }
    },
    "d25d46745ad54473a0851b0d96737c6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_207a22c1dd6641f49bd73887441ff4c2",
       "IPY_MODEL_0b229f52ad2446d7b1f2a5974415f267",
       "IPY_MODEL_777872df0e3f49adb62e92983e074920"
      ],
      "layout": "IPY_MODEL_5e788eba688445aabf4cf0a1505bdf92"
     }
    },
    "d686a57de7414161b0476d4aee408132": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0c6efb62cd3a4d09a689b9e3536bdd03",
      "placeholder": "​",
      "style": "IPY_MODEL_36391c860e3848ce9ce01055a143c862",
      "value": " 420M/420M [00:07&lt;00:00, 65.2MB/s]"
     }
    },
    "e069efadf7ec4c39b4b607380d8872ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea7fcd11d8f240d79912ea3afcde36f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6c28459b30d14043aa175c8ccaa5943c",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2170a8bbfbbc4ed69d588c1046a1fd2f",
      "value": 440473133
     }
    },
    "f2d1c366773e471c92e6434ba432d2bb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6492a9464504fa4ab445de9625ec725": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
